{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5c6dfcb7",
   "metadata": {},
   "source": [
    "# Assoziationsanalyse"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ebd409d",
   "metadata": {},
   "source": [
    "Der in diesem Notebook betrachtete Datensatz entspricht dem Datensatz aus den Folien, im Übungsmaterial finden Sie außerdem die Anwendung der Assoziationsanalyse auf einen größeren Datensatz. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49af3cf8",
   "metadata": {},
   "source": [
    "<hr style=\"border:1px solid gray\"> </hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "702fd803",
   "metadata": {},
   "source": [
    "## Inhalt    \n",
    "\n",
    "1. [Der Datensatz und die Pakete](#kap1)  \n",
    "    1.1 [Apriori-Algorithmus mit mlxtend](#kap11)  \n",
    "    1.2 [Apriori-Algorithmus mit efficient-apriori](#kap12)  \n",
    "    \n",
    "    \n",
    "2. [Fazit](#kap2)   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c90c52ab",
   "metadata": {},
   "source": [
    "<hr style=\"border:1px solid gray\"> </hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d546b728",
   "metadata": {},
   "source": [
    "## 1. Der Datensatz und die Pakete <a name=\"kap1\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b01313f8",
   "metadata": {},
   "source": [
    "Der Datensatz wird nun zunächst eingelesen. Anders als in den vorhergehenden Notebooks liegen die Daten hier zunächst als Liste statt als Pandas-Dataframe vor. Diese wird vor Anwendung des Verfahrens in das passende Format konvertiert. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd2eb0aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = [['Apfel', 'Avocado', 'Chips'],\n",
    "           ['Apfel', 'Avocado', 'Chips', 'Bier', 'Wasser'],\n",
    "           ['Avocado', 'Chips', 'Bier'],\n",
    "           ['Bier', 'Wasser'],\n",
    "           ['Avocado', 'Chips', 'Wasser'],\n",
    "           ['Apfel', 'Avocado', 'Wasser'],\n",
    "           ['Apfel', 'Avocado', 'Chips'],\n",
    "           ['Apfel', 'Avocado', 'Chips']\n",
    "          ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ec864e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d6cd08b",
   "metadata": {},
   "source": [
    "Bei einem größeren Geschäft oder Online-Shop mit vielen Artikeln entstehen durch die Dokumentation aller Einkäufe riesige Tabellen. Die Assoziationsanalyse mit dem Apriori-Algorithmus findet in diesen Listen effizient Assoziationsregeln, indem zunächt alle Kombinationen an Artikeln, deren Support größer als ein vorgegebener Wert ist, d.h. alle Artikelkombinationen, die \"häufig\" auftreten, herausgefiltert werden. Diese Kombinationen werden im Anschluss auf die enthaltenen Assoziationsregeln untersucht. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cc0c9d5",
   "metadata": {},
   "source": [
    "Die Assoziationsanalyse ist nicht in der Python-Bibliothek scikit-learn enthalten, es gibt aber mehrere Pakete, um das Verfahren dennoch in Python nutzen zu können. Hier werden zwei unterschiedliche Möglichkeiten betrachtet: \n",
    "\n",
    "Die erste Möglichkeit ist das Paket mlxtend (http://rasbt.github.io/mlxtend/user_guide/frequent_patterns/apriori/). Es kann mit dem Befehlt `!pip install mlxtend` installiert werden. \n",
    "\n",
    "Die zweite Möglichkeit ist das Paket efficient-appriori (https://efficient-apriori.readthedocs.io/en/latest/). Es kann mit dem Befehlt `!pip install efficient-apriori` installiert werden.\n",
    "\n",
    "In beiden Fällen kann das Verfahren im Anschluss genutzt werden, indem die richtigen Befehle aus den Pakten importiert werden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d149eff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install mlxtend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eac18a1c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!pip install efficient-apriori"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a161cace",
   "metadata": {},
   "source": [
    "### 1.1 Apriori-Algorithmus mit mlxtend <a name=\"kap11\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d902c53",
   "metadata": {},
   "source": [
    "Die Daten sind wie bereits angesprochen als Listen der Einkäufe gegeben. Für die Assoziationsanalyse mit mlxtend ist eine etwas andere Darstellung praktischer: Es wird eine Tabelle gebildet, deren Spalten für die Produkte stehen und deren Zeilen für die einzelnen Einkäufe stehen. Ein Eintrag ist `True` (oder 1), falls der entsprechende Artikel in diesem Einkauf enthalten ist, und sonst `False` (oder 0). Um die Tabelle in die richtige Form zu bringen, wird der `TransactionEncoder()` genutzt. Anschließend wird die Variable wie bekannt in einen Pandas-Dataframe überführt:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f5f325c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from mlxtend.preprocessing import TransactionEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82e74e39",
   "metadata": {},
   "outputs": [],
   "source": [
    "te = TransactionEncoder()\n",
    "te_matrix = te.fit(dataset).transform(dataset)\n",
    "df = pd.DataFrame(te_matrix, columns=te.columns_)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39700ce4",
   "metadata": {},
   "source": [
    "Durch dieses Vorgehen entstehen gerade bei einer großen Auswahl an Produkten eine deutlich größere Variable, in der aber viele Einträge `False` bzw. 0 sind, da jeder Einkauf nur einen Bruchteil des eigentlichen Angebots enthält. Die entstehende Variable muss also sehr effizient verarbeitet werden. \n",
    "\n",
    "Nachfolgend wird das Verfahren zunächst aus der Bibliothek mlxtend importiert und dann alle Kombinationen mit einem Support > 0.5 ausgegeben. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9544f41",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from mlxtend.frequent_patterns import apriori\n",
    "frequent_itemsets = apriori(df, min_support=0.5, use_colnames=True)\n",
    "\n",
    "frequent_itemsets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c1be8d1",
   "metadata": {},
   "source": [
    "In `frequent_itemsets` sind nun die Artikel und Artikelkombinationen und deren Support-Werte gespeichert, die einen Support größer als `min_support` (0.5) haben. Nur diese müssen für das Aufstellen der gesuchten Assoziationsregeln überhaupt weiter betrachtet werden.\n",
    "\n",
    "Geeignete Werte für `min_support` hängen stark vom Datensatz ab; zum Beispiel ist bei einem großen Online-Shop mit zehntausenden Artikeln nicht davon auszugehen, dass irgendein Support einen Wert von 0.5 erreicht, sondern `min_support` müsste viel kleiner gewählt werden.\n",
    "\n",
    "Als zweite Eigenschaft für eine gesuchte Assoziationsregel wird gefordert, dass die Konfidenz für eine Regel \"A $\\rightarrow$ B\" groß genug ist. Die Konfidenz lässt sich aus den bereits bekannten Support-Werten berechnen und das geschieht mit der Funktion `association_rules`. Dabei wird wiederum ein Grenzwert benötigt, was \"groß genug\" bedeutet, dies wird über den Parameter `min_threshold` angegeben.\n",
    "\n",
    "Nachfolgend wird das Verfahren zunächst aus der Bibliothek mlxtend importiert und dann alle Kombinationen mit einer Konfidenz > 0.5 ausgegeben. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52ab494a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlxtend.frequent_patterns import association_rules\n",
    "\n",
    "rules = association_rules(frequent_itemsets, metric=\"confidence\", min_threshold=0.8)\n",
    "rules"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a668eb67",
   "metadata": {},
   "source": [
    "Die Assoziationsregeln stehen in den Spalten \"antecedents\" (= Vorläufer) und \"consequents\" (= Folgerungen). Die erste Regel ist z.B. \"Apfel $\\rightarrow$ Avocado\", d.h. \"wer einen Apfel kauft, kauft wahrscheinlich auch eine Avocado\". \n",
    "\n",
    "Neben dem Support und der Konfidenz gibt es noch weitere Kenngrößen, anhand derer unterschieden werden kann, ob ein Zusammenhang stark genug ist, um es als Assoziationsregel in Betracht zu ziehen. Dazu gehören Lift, Leverage und Conviction (siehe weitere Spalten), mehr hierzu finden Sie im Zusatzmaterial. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fadb2805",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>Arbeitsauftrag:</b> \n",
    "\n",
    "In dem Pandas-DataFrame `rules` kann durch die korrekte Angabe von Bedingungen auf die Variable `rules['antecedents']` nun die Assoziationsregeln zu einem bestimmten Produkt des Datensatzes ausgegeben werden. Geben Sie alle Assoziationsregeln von der Produktmenge {Apfel} aus. \n",
    "\n",
    "Tipp: Betrachten Sie `rules['antecedents'] == ({'Apfel'})` .\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9549680",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Platz für Arbeitsauftrag"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e37ea69b",
   "metadata": {},
   "source": [
    "### 1.2 Apriori-Algorithmus mit efficient-apriori <a name=\"kap12\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4220440f",
   "metadata": {},
   "source": [
    "Bei der Nutzung des Verfahrens mit dem efficient-apriori können die Daten unmittelbar als Liste der Einkäufe übergeben werden und es genügt ein Befehl zur Bestimmung der Assoziationsregeln, dem sowohl der Mindestsupport als auch die Mindestkonfidenz mitgegeben werden. Das Verfahren efficient-apriori ist etwas schneller, die Ausgabe der Assoziationsregeln, nachfolgend gespeichert in der Variable `rules_ea`, ist allerdings etwas unübersichtlicher. \n",
    "\n",
    "Nachfolgend wird das Verfahren zunächst aus der Bibliothek efficient-apriori importiert und dann alle Kombinationen mit einem Support > 0.5 und einer Konfidenz > 0.5 ausgegeben. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9d1fbad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from efficient_apriori import apriori\n",
    "itemsets, rules_ea = apriori(dataset, min_support=0.5,  min_confidence=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe04c9a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "rules_ea"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4b2b1b4",
   "metadata": {},
   "source": [
    "Die oben direkt in der Tablle mitausgegebenen Werte Support und Konfidenz, sowie beispielsweise Lift und Conviction, können wür jeden Eintrag der Variable `rules` angezeigt werden. Sie entsprechen bei korrekter Lösung des Arbeitsauftrages den Werten der ersten Zeile in der oben angegebenen Tabelle. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48ef5213",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(rules_ea[0].support)\n",
    "print(rules_ea[0].confidence)\n",
    "print(rules_ea[0].lift)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02ec4c6f",
   "metadata": {},
   "source": [
    "## 2. Fazit <a name=\"kap2\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cfe55dd",
   "metadata": {},
   "source": [
    "Es wurden auf zwei Wegen der Apriori-Algorithmus auf den Beispieldatensatz aus dem Video angewendet, hierbei wurde...\n",
    "\n",
    "- festgestellt, dass Verfahren, die nicht in den üblichen Bibliotheken sind, meist über ein zusätzliches Paket gefunden werden können,\n",
    "\n",
    "\n",
    "- festgestellt, dass verschiedene Ausführungen desselben Verfahrens sich in Laufzeit, Eingabe und Ausgabe unterscheiden können,\n",
    "\n",
    "\n",
    "- wiederholt, dass die wichtigstens Hyperparameter der Mindestsupport und die Mindestkonfidenz sind, \n",
    "\n",
    "\n",
    "- beobachtet, dass es weitere Parameter im Kontext des Verfahrens gibt (bspw. Lift), welche im Übungsmaterial genauer betrachtet werden. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
