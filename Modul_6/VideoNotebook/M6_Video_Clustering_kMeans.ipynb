{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clusteranalyse mit K-Means"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die Clusteranalyse ist eine Art des unüberwachten Lernens. Es liegt hierbei eine Datenmenge vor, die aus mehreren Merkmalen besteht, anders als beim überwachten Lernen gibt es allerdings kein durch die Fragestellung gegebenes Zielmerkmal. \n",
    "\n",
    "Ziel einer Clusteranalyse ist es, Gruppen zu finden, die ähnliche Eigenschaften besitzen, sogenannte Cluster. Manchmal ist es nützlich, für jedes Cluster typische Repräsentanten angeben zu können, dies sind dann die Clusterzentren.\n",
    "\n",
    "Ein möglicher Anwendungsbereich von Clusteranalysen ist beispielsweise die Analyse sozialer Netzwerke bezüglich ihrer Nutzer:innen. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"border:1px solid gray\"> </hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inhalt\n",
    "\n",
    "1. [Künstliche Erzeugung der Datenmenge](#kap1)\n",
    "\n",
    "\n",
    "2. [k-Means](#kap2)  \n",
    "    2.1 [Durchführung](#kap21)  \n",
    "    2.2 [Visualisierung](#kap22)  \n",
    "    2.3 [Gütemaß Inertia](#kap23)  \n",
    "    2.4 [Bestimmung von k - die Ellenbogen-Methode](#kap24)  \n",
    "\n",
    "3. [Fazit](#kap3) \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"border:1px solid gray\"> </hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hide_input": true
   },
   "source": [
    "## 1. Künstliche Erzeugung der Datenmenge <a name=\"kap1\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Für eine Demonstration unterschiedlicher Arten von Clusteranalysen wird im Folgenden ein künstlicher Datensatz erzeugt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import cluster, datasets, mixture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Für die Erzeugen von Clustern von Punkten gibt es in scikit-learn eine eigene Funktion `make_blobs`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blob_centers = np.array(\n",
    "    [[1,  2],\n",
    "     [4 , 5],\n",
    "     [3,  1],\n",
    "     [2.2,  2.8],\n",
    "     ])\n",
    "blob_std = np.array([0.3, 0.2, 0.4, 0.2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = datasets.make_blobs(n_samples=500, centers=blob_centers, cluster_std=blob_std, random_state=7)  \n",
    "print(X[0:5,:])\n",
    "print(y[0:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zunächst werden für die Cluster Mittelpunkte vorgegeben. Dann werden Zufallspunkte um diese Mittelpunkte herum erzeugt. Neben den Mittelpunkten wird auch angegeben, wie stark die Zufallspunkte darum herum streuen. Dies wird durch den Parameter für die Standardabweichungen `cluster_std=blob_std` angegeben.\n",
    "\n",
    "In `y` ist abgespeichert, zu welcher Blase der zugehörige Punkt von `X` gehört. Auf diese Information wird später nicht mehr zurückgegriffen! Beim unüberwachten Lernen gibt es keine Klassenzugehörigkeit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Um unsere Datensätze schön zu plotten, wird die folgende Funktion definiert."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_clusters(X):\n",
    "    plt.scatter(X[:, 0], X[:, 1])\n",
    "    plt.xlabel(\"$x_1$\", fontsize=14)\n",
    "    plt.ylabel(\"$x_2$\", fontsize=14, rotation=0, labelpad=20)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Damit können nun die künstlich erzeugten Cluster visualisiert werden:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_clusters(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zu sehen sind also links zwei dicht beieinanderliegende Cluster, die sich nur schlecht unterscheiden lassen, ein weiterer Cluster oben rechts, und ein etwas weniger dichter Cluster unten rechts.\n",
    "Das Ziel der Clusteranalyse ist es, diese Cluster zuverlässig zu erkennen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"border:1px solid gray\"> </hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. k-Means <a name=\"kap2\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Durchführung <a name=\"kap21\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Das k-Means-Verfahren beginnt mit der Festlegung der Anzahl der Cluster: k. Anschließend werden folgende Berechnungsschritte durchgeführt:\n",
    "- k-Means wählt zunächst zufällig k Punkte aus dem Datensatz aus und setzt diese als vorläufige Clustermittelpunkte. \n",
    "\n",
    "- Jetzt werden die Cluster gebildet, indem jeder Punkt dem nächstgelegenen Clustermittelpunkt zugeordnet wird. Da die Clustermittelpunkte im ersten Schritt zufällig gewählt wurden, sind die Cluster noch sehr unausgewogen und zeigen noch nicht das gewünschte Ergebnis. \n",
    "\n",
    "- Aus diesen Clustern werden neue Zentren ermittelt, indem die Mittelwerte der Clusterpunkte berechnet werden. (Diese neuen Mittelpunkte müssen nicht unbedingt Punkte des Datensatzes sein!) \n",
    "\n",
    "- Mit diesen neuen Mittelpunkten wird das Verfahren wiederholt wodurch wieder neue Cluster entsehen. \n",
    "\n",
    "- Das Vorgehen wird solange wiederholt, bis sich die gebildeten Cluster nicht mehr ändern."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Das k-Means-Verfahren wird nun für die künstlich erzeugte Punktemenge durchgefüht. Die Syntax von scikit-learn ist beim unüberwachten Lernen ganz ähnlich zu der beim überwachten Lernen: Das Modell wird zunächst initialisiert und dann gefittet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 4\n",
    "kmeans = KMeans(n_clusters=k, random_state=0)\n",
    "\n",
    "y_pred = kmeans.fit_predict(X)\n",
    "print(\"Anzahl der Iterationen:\", kmeans.n_iter_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die Ausgabe zeigt, dass das Verfahren bereits nach 2 Iterationsschritten endet. Das Ergebnis ist bereits stabil. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Visualisierung <a name=\"kap22\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zur Darstellung der Ergebnisse wird jeder Punkt einem Cluster zugeordnet (die Cluster sind von 0 bis k-1 durchnummeriert) und anschließend eine Funktion zur Visualisierung der Cluster ausgeführt:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_kmeans(X, mod):                                     # mod ist das trainierte Modell\n",
    "    plt.scatter(X[:,0], X[:,1], c=mod.labels_.astype(float)) # mod.labels_ ist dasselbe wie y_pred\n",
    "    plt.scatter(mod.cluster_centers_[:, 0], mod.cluster_centers_[:, 1], marker='x', s=2, linewidths=12, color='k')\n",
    "    plt.xlabel(\"$x_1$\", fontsize=14)\n",
    "    plt.ylabel(\"$x_2$\", fontsize=14, rotation=0, labelpad=20)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(kmeans.cluster_centers_)\n",
    "plot_kmeans(X, kmeans)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die Cluster werden also sehr gut erkannt, und tatsächlich liegen die erhaltenen Clustermittelpunkte sehr nah an den oben festgelegten ``blob_centers``."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Gütemaß Inertia <a name=\"kap23\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bisher wurde die Güte einer Clusterung nur visuell überprüft. Um sie maschinell zu prüfen, wird ein Maß benötigt, dass die Güte als Zahl ausdrückt. \n",
    "\n",
    "*Inertia* (Trägheit) oder *within-cluster sum of squares (wcss)* (dt. Summe der Quadrate innerhalb der Cluster) ist ein Gütemaß, das sich aus der Summe der quadratischen Abweichungen der Punkten zu ihren Clustermittelpunkten errechnet. Je kleiner der Wert, desto besser ist die Clusterung. Scikit-learn berechnet den Inertia-Wert automatisch, er kann mit `kmeans.inertia_` aufgerufen werden:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(Um die Inertia-Werte der bisher betrachteten Situationen besser einordnen zu können, werden die Cluster erneut als Plot ausgegeben.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Inertia bei Beispiel:\", kmeans.inertia_)\n",
    "plot_kmeans(X, kmeans)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nun werden als Startwerte nur Werte gewählt, die im oberen rechten Cluster liegen und dann erneut eine Clusteranalyse vorgenommen:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "startwerte = np.array([[3.6, 4.6], [3.8, 5.2],[4.2, 4.9],[4, 4.9]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 4\n",
    "kmeans_schlecht = KMeans(n_clusters=k, init=startwerte, n_init=1, random_state=0).fit(X)\n",
    "print(\"Anzahl Iterationen:\", kmeans_schlecht.n_iter_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bei schlecht gewählten Startwerten sind mehr Iterationsschritte nötig. Hier sind es 4 Schritte im Vergleich von 2 oben. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Inertia bei den schlecht gewählten Startwerten:\", kmeans_schlecht.inertia_)\n",
    "plot_kmeans(X, kmeans_schlecht)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zu sehen ist, dass in diesem Beispiel das obere Cluster in drei aufgeteilt wird, während die übrigen Datenpunkte einem großen Cluster zugeordnet werden. Der Inertia-Wert ist nun bedeutend schlechter!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Bestimmung von k &ndash; die Ellenbogen-Methode <a name=\"kap24\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bisher wurde die Anzahl der zu bestimmenden Cluster k immer graphisch anhand eines Plots der Punktemenge ausgewählt. Doch wie ist das Vorgehen, wenn es mehr als zwei bzw. drei Merkmale gibt? In diesem Fall ist es nicht möglich, am Plot zu sehen, wie viele Cluster gebildet werden sollten, also wie das k zu wählen ist.\n",
    "\n",
    "Eine Idee könnte sein, verschiedene Werte von k auszuprobieren, und denjenigen mit dem besten (d.h. kleinsten) Inertia-Wert zu wählen. Dieses Vorgehen ist allerdings problematisch, da Inertia mit steigendem k automatisch kleiner wird, unabhängig davon, ob das gewählte k sinnvoll ist oder nicht. Intuitiv lässt sich das einfach erklären: Wenn k als die Anzahl der Punkte im Datensatz gewählt wird, dann bildet jeder Punkt ein eigenes Cluster, und der Abstand zum Clustermittelpunkt ist 0, und damit ist auch Inertia gleich 0. Ein kleiner Intertia-Wert alleine ist also nicht aussagekräftig. \n",
    "\n",
    "Dennoch kann Inertia helfen: Die Betrachtung der Veränderung von Inertia in Abhängigkeit von k führt in den meisten Fällen zu einem Verlauf, bei dem Inertia bei der richtigen Wahl von k stark und danach nur noch schwach abnimmt. Der entstehende \"Ellenbogen\" wird in der folgenden Kurve, in der für jedes k der Inertia-Wert für den ursprünglichen Datensatz an Clustern abgetragen wird, dargestellt:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inertias = []\n",
    "number_clusters = range(1,8)\n",
    "\n",
    "for i in number_clusters:\n",
    "    kmeans_i = KMeans(i, random_state=0).fit(X)\n",
    "    inertias.append(kmeans_i.inertia_)\n",
    "    print(\"Inertia für k =\",i,\"ist:\",inertias[i-1])\n",
    "\n",
    "plt.plot(number_clusters, inertias);\n",
    "plt.title('Ellenbogenkurve')\n",
    "plt.xlabel('Anzahl der Cluster (\"k\")', labelpad=10)\n",
    "plt.ylabel('Inertia', labelpad=10)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bis zum Wert 3 nimmt die Inertia deutlich ab. Von 3 auf 4 ist noch einmal eine größere Verbesserung erkennbar. Ab einem Wert von k=4 gibt es nur noch eine geringe Änderung. Daher ist k=4 der günstigste Wert (der Punkt am Ende des \"Ellenbogens\"). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Das k-Means-Verfahren funktioniert am besten, wenn die gesuchten Cluster eine \"runde\" Form haben. \n",
    "In Daten treten jedoch auch komplexere Strukturen auf. Dann liefert k-Means keine so guten Ergebnisse mehr. In diesem Fall können andere Verfahren (vgl. Modul 7) eingesetzt werden.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>Arbeitsaufträge:</b>   \n",
    "    \n",
    "1. Die in Kapitel 2.2 in lila und gelb dargestellen Cluster liegen nah beieinander. Verändern Sie die Parameter des k-Means so, dass diese beiden Cluster zu einem zusammengefasst werden.\n",
    "\n",
    "2. Nutzen Sie die Funktion `make_blobs`, um eine künstliche Punktemenge mit 6 Zentren zu erzeugen und visualisieren Sie diese.  \n",
    "Wenden Sie auf die so erzeugte Punktemenge das kmeans-Verfahren an und geben Sie einen Plot der Clusterung aus.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Platz für Arbeitsauftrag 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Platz für Arbeitsauftrag 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Fazit <a name=\"kap3\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die Anwenudung des K-Means mit k=6 zeigt, dass fast alle Punkte dem Cluster geordnet werden, von dem sie auch erzeugt wurden. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Es wurde das k-Means Verfahren auf einen selbsterzeugten Beispieldatensatz angewendet. Hierbei wurde...\n",
    "\n",
    "- gezeigt, dass die Umsetzung des Verfahrens der Syntax Logik der überwachten Lernverfahren entspricht, \n",
    "\n",
    "- der Einfluss des Hyperparameters k und der Auswahl der Startwerte gezeigt, \n",
    "\n",
    "- die Bestimmung des Gütemaßes Inertia und die Durchführung der Ellenbogenmethode thematisiert. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DaLI-DM",
   "language": "python",
   "name": "DaLI-DM"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
