{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <p style='margin-bottom:-30px'><font color='darkblue'>Modul 4: Übungsmaterial Klassifikation &#8211; Was macht Schokolade lecker?</font>&nbsp; <font size='6'>&#x1F36B;</font></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"border:1px solid gray\"> </hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In diesem Notebook wird der Datensatz zur Schokoladenbewertung, der bereits aus dem Übungsnotebook aus Modul 2 bekannt ist, genauer betrachtet. Auf Grundlage der Daten soll ein Klassifikationsmodell erstellt werden, anhand dessen sich bestimmen lässt, was eine leckere Schokolade ausmacht."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='darkblue'>Inhalt</font>\n",
    "\n",
    "\n",
    "1. [Datenverständnis und Datenvorbereitung](#kap1)  \n",
    "    1.1 [Datensatz einlesen und erforschen](#kap11)  \n",
    "    1.2 [Datenvorbereitung](#kap12)    \n",
    "    \n",
    "\n",
    "2. [Modellierung](#kap2)    \n",
    "    2.1 [Erste Modellierung](#kap21)  \n",
    "    &emsp; &ensp;2.1.1 [Entscheidungsbaum](#kap211)  \n",
    "    &emsp; &ensp;2.1.2 [Random Forest](#kap212)  \n",
    "    2.2 [Zweite Modellierung](#kap22)   \n",
    "\n",
    "\n",
    "3. [Fazit](#kap3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"border:1px solid gray\"> </hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='darkblue'>1. Datenverständnis und Datenvorbereitung</font> <a name=\"kap1\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='darkblue'>1.1  Datensatz einlesen und erforschen</font> <a name=\"kap11\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In diesem Beispiel soll der Datensatz mit Merkmalen von Schokoladenriegeln untersucht werden, welcher bereits in Modul 2 bereiningt wurde. Der ursprüngliche Datensatz wurde auf <a href=\"http://flavorsofcacao.com/chocolate_database.html\">Flavors of Cacao</a> veröffentlicht und kann auch über <a href=\"https://www.kaggle.com/andrewmvd/chocolate-ratings\">Kaggle</a> heruntergeladen werden. Hier wurde er vorher leicht verändert.\n",
    "\n",
    "Mit ihm soll in diesem Modul ein Modell zur Bewertung des Geschmacks von Schokoladenriegeln anhand verschiedener Merkmale erstellt werden. Dabei soll das Rating (die 3 Klassen) als Zielmerkmal ausgewählt werden. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zunächst werden die benötigten Bibliotheken eingebunden, sowie der in Modul 2 vorbereitete Datensatz eingelesen und ein Überblick angezeigt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-31T08:10:50.850875Z",
     "iopub.status.busy": "2022-01-31T08:10:50.850554Z",
     "iopub.status.idle": "2022-01-31T08:10:50.890282Z",
     "shell.execute_reply": "2022-01-31T08:10:50.888921Z",
     "shell.execute_reply.started": "2022-01-31T08:10:50.850838Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('M4_Uebung_Schokolade_bereinigt.csv')\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-31T08:10:50.893037Z",
     "iopub.status.busy": "2022-01-31T08:10:50.892662Z",
     "iopub.status.idle": "2022-01-31T08:10:50.911791Z",
     "shell.execute_reply": "2022-01-31T08:10:50.910803Z",
     "shell.execute_reply.started": "2022-01-31T08:10:50.892988Z"
    }
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Der Datensatz enthält Informationen zur Herstellung, Zusammensetzung und Geschmacksbewertung von Schokoladenriegeln. Die Merkmale werden in der nachfolgenden Tabelle erläutert."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table align='left'>\n",
    "    <thead>\n",
    "        <tr>\n",
    "          <th style=\"text-align:left\">Spaltenname</th>\n",
    "          <th style=\"text-align:left\">Bedeutung</th>\n",
    "          <th style=\"text-align:left\">Weitere Informationen</th>\n",
    "        </tr>\n",
    "    </thead>\n",
    "    <tr>\n",
    "    <td style=\"text-align:left\">Company</td>\n",
    "    <td style=\"text-align:left\">Hersteller</td>\n",
    "    <td style=\"text-align:left\">-</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "    <td style=\"text-align:left\">Company Location</td>\n",
    "    <td style=\"text-align:left\">Herstellungsort</td>\n",
    "    <td style=\"text-align:left\">Im Datensatz sind nur Riegel enthalten, die in den USA oder Kanada produziert wurden.</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "    <td style=\"text-align:left\">Review Date</td>\n",
    "    <td style=\"text-align:left\">Jahr der Bewertung</td>\n",
    "    <td style=\"text-align:left\">-</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "    <td style=\"text-align:left; vertical-align: top\">Country of Bean Origin</td>\n",
    "    <td style=\"text-align:left; vertical-align: top\">Herkunftsland der verwendeten Kakaobohne</td>\n",
    "    <td style=\"text-align:left; vertical-align: top\">-</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "    <td style=\"text-align:left; vertical-align: top\">Specific Bean Origin or Bar Name</td>\n",
    "    <td style=\"text-align:left; vertical-align: top\">Name der verwendeten Bohne /<br>Name des Riegels</td>\n",
    "    <td style=\"text-align:left; vertical-align: top\">-</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "    <td style=\"text-align:left\">Cocoa Percent</td>\n",
    "    <td style=\"text-align:left\">Kakaoanteil</td>\n",
    "    <td style=\"text-align:left\">[%]</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "    <td style=\"text-align:left; vertical-align: top\">Rating</td>\n",
    "    <td style=\"text-align:left; vertical-align: top\">Bewertung</td>\n",
    "    <td style=\"text-align:left; vertical-align: top\">3 = sehr empfehlenswert <br>2 = empfehlenswert <br>1 = enttäuschend</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "    <td style=\"text-align:left; vertical-align: top\">rich cocoa, fatty, [...], dirty, bold</td>\n",
    "    <td style=\"text-align:left; vertical-align: top\">Einprägsamste Merkmale</td>\n",
    "    <td style=\"text-align:left; vertical-align: top\">Es handelt sich hierbei um die Ausprägungen der einprägsamsten Merkmale aus dem Übungsnotebook des Moduls 2. Aus diesen wurden mittels One-Hot-Encoding eigene Datenspalten gebildet. Die Ausprägungen sind somit 0 oder 1.</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "    <td style=\"text-align:left\">Number of Ingredients</td>\n",
    "    <td style=\"text-align:left\">Anzahl der Zutaten</td>\n",
    "    <td style=\"text-align:left\">-</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "    <td style=\"text-align:left\">b</td>\n",
    "    <td style=\"text-align:left\">Bohnen</td>\n",
    "    <td style=\"text-align:left\">0 / 1</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "    <td style=\"text-align:left\">s</td>\n",
    "        <td style=\"text-align:left\">Zucker</td>\n",
    "    <td style=\"text-align:left\">0 / 1</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "    <td style=\"text-align:left\">c</td>\n",
    "    <td style=\"text-align:left\">Kakaobutter</td>\n",
    "    <td style=\"text-align:left\">0 / 1</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "    <td style=\"text-align:left\">l</td>\n",
    "    <td style=\"text-align:left\">Lecithin</td>\n",
    "    <td style=\"text-align:left\">0 / 1</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "    <td style=\"text-align:left\">v</td>\n",
    "    <td style=\"text-align:left\">Vanille</td>\n",
    "    <td style=\"text-align:left\">0 / 1</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "    <td style=\"text-align:left\">sa</td>\n",
    "    <td style=\"text-align:left\">Salz</td>\n",
    "    <td style=\"text-align:left\">0 / 1</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "    <td style=\"text-align:left\">s*</td>\n",
    "    <td style=\"text-align:left\">Süßungsmittel</td>\n",
    "    <td style=\"text-align:left\">0 / 1</td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='darkblue'>1.2. Datenvorbereitung</font> <a name=\"kap12\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zur besseren Übersichtlichkeit des Datensatzes werden nun zunächst einige Merkmale gelöscht, die in der folgenden Klassifikation nicht verwendet werden sollen. Dies liegt entweder daran, dass sie höchstwahrscheinlich keinen Einfluss auf den Geschmack haben (bspw. `Review Date`) oder nur schwierig weiterverarbeitet werden können (bspw. `Country of Bean Origin`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(\"Company (Manufacturer)\", axis=1)\n",
    "df = df.drop(\"Company Location\", axis=1)\n",
    "df = df.drop(\"Review Date\", axis=1) \n",
    "df = df.drop(\"Specific Bean Origin or Bar Name\", axis=1) \n",
    "df = df.drop(\"Country of Bean Origin\", axis=1) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nun werden die Daten in Trainings- und Testdatenmenge aufgeteilt. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_set,test_set = train_test_split(df, random_state=0, test_size=0.2, stratify = df['Rating'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Anschließend werden die Daten mit dem Standardscaler auf die Daten der Trainingsmenge skaliert."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Nur die Merkmale werden standardisiert, daher wird eine Liste erstellt, die nur die Merkmale ohne das Zielmerkmal enthält\n",
    "features = list(df.drop(['Rating'], axis=1).columns)\n",
    "\n",
    "# Skalierung wird an train_set angepasst\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(train_set[features])\n",
    "\n",
    "# Skalierung der Trainingsdaten\n",
    "train_features_scaled = pd.DataFrame(scaler.transform(train_set[features]), columns=features, index=train_set.index)\n",
    "# Zusammenfügen der skalierten Merkmale und das Zielmerkmal (nicht skaliert) zu einem Dataframe\n",
    "train_set_scaled = pd.concat([train_features_scaled, train_set['Rating']], axis=1)\n",
    "\n",
    "# Skalierung der Testdaten\n",
    "test_features_scaled = pd.DataFrame(scaler.transform(test_set[features]), columns=features, index=test_set.index)\n",
    "# Zusammenfügen der skalierten Merkmale und das Zielmerkmal (nicht skaliert) zu einem Dataframe\n",
    "test_set_scaled = pd.concat([test_features_scaled, test_set['Rating']], axis=1)\n",
    "\n",
    "train_set_scaled.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Da das Zielmerkmal das Rating ist, werden die Trainings- und Testdaten passend in Eingabe- und Ausgabemerkmale geteilt. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trainingsdaten für die Modellierung mit ausgewählten Merkmalen\n",
    "X_train = train_set_scaled.drop([\"Rating\"], axis=1)\n",
    "y_train = train_set_scaled[['Rating']].values.ravel() # Befehl verändert die Form der Variable und verhindert so eine sonst auftretende Warnung \n",
    "\n",
    "# Testdaten für die Modellierung mit ausgewählten Merkmalen\n",
    "X_test = test_set_scaled.drop([\"Rating\"], axis=1)\n",
    "y_test = test_set_scaled[['Rating']].values.ravel() # Befehl verändert die Form der Variable und verhindert so eine sonst auftretende Warnung "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"border:1px solid gray\"> </hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='darkblue'>2. Modellierung</font> <a name=\"kap2\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wenn wie in diesem Beispiel mehr als zwei Klassen vorliegen, spricht man von Klassifikatoren mit mehreren Kategorien oder auch von multinomialen Klassifikatoren. Hierbei gibt es einige Unterschiede zu beachten:\n",
    "\n",
    "Bei der Fehleranalyse kann weiterhin die Korrektklassifikationsrate und die Konfusionsmatrix berechnet werden. Precision und Recall können zwar je bezüglich einer der Klassen bestimmt werden, dies ist aber aufwändiger, da vorher alle anderen Klassen als negative Klasse zusammengefasst werden müssen.\n",
    "\n",
    "Viele Methoden der Klassifikation mit zwei Klassen lassen sich erweitern auf mehrere Klassen. Von den in diesem Kurs vorgestellten ist nur die Support Vector Machine nicht auf mehr als zwei Klassen anwendbar. Hier kann aber die \"Einer gegen Alle\"-Strategie angewendet werden: Der erste Klassifikator entscheidet, ob die erste Klasse vorliegt oder nicht. Der zweite, ob die zweite Klasse vorliegt usw. bis zur Gesamtanzahl der Klassen. Aus diesen Einzelklassifikatoren wird dann die Entscheidung mit dem höchsten Score als Gesamtentscheidung herausgegriffen. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='darkblue'>2.1 Erste Modellierung</font> <a name=\"kap21\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Für ein erstes Modell sollen die Merkmale, welche sich aus der `Most Memorable Characteristics` ergeben haben, für eine Modellierung umgangen werden. So würde sich eine Aussage rein aus den Zutaten des Riegels ableiten lassen. Um dies umzusetzen, werden die Variablen auf diese Merkmale eingeschränkt: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_teil = X_train[['Cocoa Percent','Number of Ingredients','b','s','c','l','v','sa','s*']]\n",
    "X_test_teil = X_test[['Cocoa Percent','Number of Ingredients','b','s','c','l','v','sa','s*']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='darkblue'>2.1.1 Entscheidungsbaum</font> <a name=\"kap211\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aus dem Video ist bereits der Entscheidungsbaum bekannt. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "&#128187; <b>Arbeitsauftrag:</b> \n",
    "\n",
    "Modellieren Sie einen Entscheidungsbaum mit `max_depth = 10`, indem Sie die nachfolgende Zelle ergänzen. Geben Sie anschließend die Konfusionsmatrix für die Testdaten aus und interpretieren Sie das Ergebnis. Was geben die Einträge in den Zeilen und Spalten an?\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-31T08:10:53.684353Z",
     "iopub.status.busy": "2022-01-31T08:10:53.684078Z",
     "iopub.status.idle": "2022-01-31T08:10:53.72443Z",
     "shell.execute_reply": "2022-01-31T08:10:53.723473Z",
     "shell.execute_reply.started": "2022-01-31T08:10:53.684298Z"
    }
   },
   "outputs": [],
   "source": [
    "# Ergänzen Sie die zweite Zeile\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "# clf_dt = #\n",
    "clf_dt.fit(X_train_teil,y_train)\n",
    "print(\"Korrektklassifikationsrate auf Trainingsdaten:\", clf_dt.score(X_train_teil, y_train))\n",
    "print(\"Korrektklassifikationsrate auf Testdaten:\",clf_dt.score(X_test_teil,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Geben Sie in diese Zelle die Befehle zur Ausgabe der Konfusionsmatrix an (Achtung: Einbindung des Moduls nicht vergessen)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interpretation: Die Konfusionsmatrix besitzt nun genauso viele Zeilen und Spalten wie Klassen vorhanden sind, hier sind es daher 3 Zeilen und Spalten.\n",
    "\n",
    "In den Zeilen stehen wieder die tatsächlichen Werte der jeweiligen Klassen, in den Spalten die vorhergesagten Werte. So bedeutet z.B. die Zahl `217` in der zweiten Zeile und zweiten Spalte, dass in 217 Fällen für Riegel der Klasse 2 auch diese Klasse vorhergesagt wurde. Allgemein lässt sich formulieren: alle richtigen Vorhersagen stehen auf der Hauptdiagonalen der Matrix:  \n",
    "<br>\n",
    "\n",
    "<span style='font-family:monospace'>\n",
    "    [[ <span style='background :gold'>0</span>   &ensp;&ensp;   10   &ensp;&ensp;   0]    <br>    \n",
    "    &thinsp;&thinsp;&thinsp;[ 1  &ensp; <span style='background :gold'>217</span> &ensp; 69]    <br>\n",
    "    &thinsp;&thinsp;&thinsp;[ 0  &ensp;  139  &ensp;  <span style='background :gold'>53</span>]]\n",
    "</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die Konfusionsmatrix zeigt, wie stark die einzelnen Klassen besetzt sind und wo noch Fehler bei der Vorhersage gemacht werden.\n",
    "Die Zeilensummen geben an, wie viele Testfälle dieser Klasse in der Testmenge sind:\n",
    "- Für die erste Klasse sind das 10 Testfälle.\n",
    "- Die zweite Klasse ist 1+217+69 = 287 Mal vertreten.\n",
    "- Die dritte Klasse hat 139+53 = 192 Testfälle.\n",
    "\n",
    "Auf der Diagonalen stehen die Anzahlen der richtig erkannten Testfälle:   \n",
    "- Die erste Klasse wurde niemals richtig erkannt. Alle Testfälle zur ersten Klasse wurden der Klasse 2 zugeordnet. \n",
    "- Die zweite Klasse wurde 217 mal richtig erkannt. 1 Testfall wurde der ersten Klasse zugeordent, 69 Testfälle der dritten Klasse.\n",
    "- 139 Elemente der Klasse 3 wurden der Klasse 2 zugeordnet. usw. \n",
    "\n",
    "Die Konfusionsmatrix gibt eine tiefere Einsicht bei der Fehleranalyse. Hier sehen Sie z.B. dass die größte Anzahl der falschen Klassifizierungen bei den 139 Fällen von Klasse 3-Testfällen war, die in Klasse 2 eingeordnet wurden. Es könnte nun überlegt werden, wie diese beiden Klassen besser zu unterscheiden sind. \n",
    "\n",
    "Anhand der Konfusionsmatrix kann auch die Berechnung der Korrektklassifikationsrate nachvollzogen werden:\n",
    "\n",
    "Korrekt klassifiziert sind alle Einträge auf der Diagonalen der Matrix, hier:\n",
    "0 + 217 + 53 = 270\n",
    "\n",
    "Die Gesamtheit aller Testfälle ist die Summe aller Einträge in der Matrix, hier zeilenweise vorgegangen:\n",
    "0+10+0 + 1+217+69 + 0+139+53 = 489\n",
    "\n",
    "Die Korrektklassifikationsrate ist dann 270 &divide; 489 = 0,552...."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Eine Variation der Tiefe des Baumes und anschließende Ausgabe der Korrektklassifikationsrate kann einen Hinweis auf die beste Tiefe geben: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(2,20):\n",
    "    clf_dt = DecisionTreeClassifier(max_depth = i)\n",
    "    clf_dt.fit(X_train_teil,y_train)\n",
    "    print(\"i = \", i)\n",
    "    print(\"Korrektklassifikationsrate auf Testdaten:\",clf_dt.score(X_test_teil,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Der beste Entscheidungsbaum hat eine Tiefe von 5, es sind also sehr viele Unterscheidungen nötig. Die Korrektklassifikationsrate liegt in diesem Fall bei knapp 59%, was aber im Kontext der Anzahl der Klassen interpretiert werden muss: Bei drei Klassen liegt die Ratewahrscheinlichkeit bei 1/3 = 33,33%, also ist die Korrektklassifikationsrate deutlich höher als eine zufällige Entscheidung. \n",
    "\n",
    "Es soll nun noch ein neues Verfahren thematisiert werden: Der Random Forest. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='darkblue'>2.1.2 Random Forest</font> <a name=\"kap212\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Forests oder auf Deutsch \"Zufallswälder\" basieren auf Entscheidungsbäumen: \n",
    "Aus den Trainingsdaten werden Teilmengen gebildet, für die jeweils ein einzelner Entscheidungsbaum trainiert wird. Es entstehen daher mehrere Entscheidungsbäume, die bei der Vorhersage unterschiedliche Klassifikationen vornehmen können. Die Klasse, die dabei am häufigsten auftritt, bestimmt die endgültige Klassenzuordnung und ist damit die Vorhersage des Random Forest.\n",
    "\n",
    "Der einzelne Entscheidungsbaum muss dabei nicht unbedingt besonders gut sein. Wichtig beim Random Forest ist es eher, möglichst unterschiedliche Entscheidungsbäume zu erstellen. Diese produzieren dann unterschiedliche Fehlertypen, die sich über die Menge der Bäume dann gegenseitig aufheben. \n",
    "\n",
    "Das Modell des Random Forests ist jedoch nicht mehr so leicht nachvollziehbar wie das eines einzelnen Entscheidungsbaumes, d.h. die Erklärbarkeit des Modells geht verloren."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Es soll nun zu dem oben definierten Datensatz ein Random Forest trainiert werden, die Syntax entspricht der bereits bekannten."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-31T08:10:53.726742Z",
     "iopub.status.busy": "2022-01-31T08:10:53.726211Z",
     "iopub.status.idle": "2022-01-31T08:10:53.766222Z",
     "shell.execute_reply": "2022-01-31T08:10:53.765397Z",
     "shell.execute_reply.started": "2022-01-31T08:10:53.726693Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "clf_rf = RandomForestClassifier(max_depth=5, n_estimators=10) # n_estimators gibt die Anzahl der Bäume im Wald an\n",
    "clf_rf.fit(X_train_teil, y_train)\n",
    "print(\"Korrektklassifikationsrate auf Trainingsdaten:\", clf_rf.score(X_train_teil, y_train))\n",
    "print(\"Korrektklassifikationsrate auf Testdaten:\",clf_rf.score(X_test_teil,y_test))\n",
    "\n",
    "y_pred_rf = clf_rf.predict(X_test_teil)\n",
    "print(confusion_matrix(y_test, y_pred_rf))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Der Random Forest bringt offenbar zunächst kein besseres Modell hervor. Ein Random Forest besitzt viele Hyperparameter, die optimiert werden sollten.  \n",
    "Die beiden wichtigsten sind die Tiefe der Bäume `max_depth`  und ihre Anzahl `n_estimators`.\n",
    "\n",
    "Um beide Parameter gleichzeitig zu variieren, kann eine Doppelschleife genutzt werden:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-31T08:10:53.768405Z",
     "iopub.status.busy": "2022-01-31T08:10:53.76806Z",
     "iopub.status.idle": "2022-01-31T08:10:56.273125Z",
     "shell.execute_reply": "2022-01-31T08:10:56.272061Z",
     "shell.execute_reply.started": "2022-01-31T08:10:53.768357Z"
    }
   },
   "outputs": [],
   "source": [
    "for j in [50, 100, 300, 500]:\n",
    "    for i in [5, 10, 15]:\n",
    "        clf = RandomForestClassifier(max_depth=i, n_estimators=j, random_state=0)\n",
    "        clf.fit(X_train_teil, y_train)\n",
    "        print(\"i= \", i, \" j = \", j)\n",
    "        print(clf.score(X_test_teil, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die beste Korrektklassifikationsrate wird bei `max_depth = 5` und `n_estimators=50` erreicht. Es wäre möglich, an dieser Stelle die Suche nach den besten Parametern zu verfeinern, indem noch mehr Werte ausprobiert werden, allerdings liegt die Korrektklassifikationsrate auch hier wieder bei ca. 59%. Es scheint also, als wäre hier keine Optimierung bezüglich der Korrektklassifikationsrate möglich, deshalb sollen nun doch auch die `Most Memorable Characteristics` in die Modellierung mit einbezogen werden. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='darkblue'>2.2 Zweite Modellierung</font> <a name=\"kap22\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Da für die erste Modellierung lediglich auf die Variablen `X_train_teil` und `X_test_teil` zurückgegriffen wurde, kann nun mit der Variable `X_train` und `X_test` fortgefahren werden. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "&#128187; <b>Arbeitsauftrag:</b> \n",
    "\n",
    "Nutzen Sie die Bausteine von Kapitel 2.1.1, um einen Entscheidungsbaum mit `max_depth = 10` zu modellieren. Geben Sie anschließend die Korrektklassifikationsraten und die Konfusionsmatrix aus.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Platz für Arbeitsauftrag"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Das Ergebnis zeigt, dass mit den neu hinzugefügten Merkmalen eine deutlich bessere Modellierung möglich ist.  \n",
    "Vielleicht liefert hier nun auch der Random Forest ein besseres Ergebnis? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "&#128187; <b>Arbeitsauftrag:</b> \n",
    "\n",
    "Nutzen Sie die Bausteine von Kapitel 2.1.2, um einen Random Forest inklusive einer Suche nach den besten Paramtern mit einer Doppelschleife für die Parameter `max_depth`  und `n_estimators` zu modellieren. Geben Sie in jeder Runde die Korrektklassifikationsrate der Testmenge aus. \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Platz für Arbeitsauftrag"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die beste Korrektklassifikationsrate wird bei `max_depth = 15` und `n_estimators=50` erreicht. Nachfolgend wird das Netz noch einmal verfeinert: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for j in [40, 45, 50, 55, 60]:\n",
    "    for i in [13, 14, 15, 16, 17]:\n",
    "        clf = RandomForestClassifier(max_depth=i, n_estimators=j, random_state=0)\n",
    "        clf.fit(X_train, y_train)\n",
    "        print(\"i= \", i, \" j = \", j)\n",
    "        print(clf.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Das beste Ergebnis wird für `i=17`und  `j = 60` erreicht. Die Konfusionsmatrix gibt abschließend an, wo die Verbesserungen stattgefunden haben:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = RandomForestClassifier(max_depth=17, n_estimators=60, random_state=0)\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred_rf_neu = clf.predict(X_test)\n",
    "print(confusion_matrix(y_test, y_pred_rf_neu))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die Modellierung zeigt, dass der Einbezug der `Most Memorable Characteristics`, obwohl er umgangen werden sollte, eine Verbesserung des Modells mit sich bringt. Durch die in Modul 2 durchgeführte Aufspaltung des Merkmals könnte eine Untersuchung dieses Ergebnisses zurückspiegeln, welche `Most Memorable Characteristics` zu einem besonders guten Riegel führt. Dies wäre eine logisch nachfolgende Untersuchung. \n",
    "\n",
    "Wie beispielsweise auch im Video thematisiert wurde, ist ein schlichtes Ausprobieren, bei welchen Parametern eine optimierte Korrektklassifikationsrate erreicht wird, nicht immer zielführend."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Allgemein erzielen Random Forests in vielen Anwendungen bei mittelgroßen Datensätzen sehr gute Ergebnisse. \n",
    "\n",
    "Es gibt inzwischen einige Verbesserungen, die die Bäume schneller und mit weniger Rechenkapazität berechnen können.  \n",
    "Weit verbreitet sind <a href=\"https://xgboost.readthedocs.io/en/stable/\">xgboost</a> und <a href=\"https://lightgbm.readthedocs.io/en/latest/index.html\">LigthGBM</a>.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"border:1px solid gray\"> </hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='darkblue'>3. Fazit</font> <a name=\"kap3\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dieses Notebook hat\n",
    "- eine Klassifikation mit mehr als zwei Klassen gezeigt.\n",
    "- Ihre Fähigkeiten bei der Vorverarbeitung der Daten erweitert.\n",
    "- ein neues Klassifikationsverfahren, nämlich das Random Forest Verfahren, eingeführt. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DaLI-DM",
   "language": "python",
   "name": "python-dali-dm"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
