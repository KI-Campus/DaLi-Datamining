{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Klassifikation: Vorhersage von Weinqualitäten"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quelle:\n",
    "https://archive.ics.uci.edu/ml/datasets/wine+quality  \n",
    "\n",
    "Der Datensatz enhält Daten über die  chemischen Zusammensetzung von Rotweinen und ihrer Qualität. Er wurde veröffentlicht von Paulo Cortez, Antonio Cerdeira, Fernando Almeida, Telmo Matos and Jose Reis. (ISSN: 0167-9236)\n",
    "\n",
    "Der Datensatz wurde für die Verwendung in diesem Notebook leicht modifiziert."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"border:1px solid gray\"> </hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inhalt\n",
    "\n",
    "\n",
    "1. [Geschäftverständnis / Aufgabe](#kap1)\n",
    "\n",
    "\n",
    "2. [Datenverständnis](#kap2) \n",
    "\n",
    "\n",
    "3. [Datenvorbereitung](#kap3) \n",
    "\n",
    "    3.1 [Aufteilung in Trainings- und Testdatensatz](#kap31)  \n",
    "    3.2 [Standardisierung der Daten](#kap32)  \n",
    "    3.3 [Visualisierung](#kap33)  \n",
    "    3.4 [Merkmalsauswahl anhand der Korrelationsmatrix](#kap34) \n",
    "\n",
    "\n",
    "4. [Modellierung](#kap4) \n",
    "\n",
    "    4.1 [Entscheidungsbaum](#kap41)  \n",
    "    4.2 [kNN (k-Nächste Nachbarn)](#kap42)  \n",
    "    4.3 [SVM (Support Vector Machine)](#kap43)    \n",
    "    \n",
    "\n",
    "5. [Fazit](#kap5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"border:1px solid gray\"> </hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Geschäftsverständnis / Aufgabe <a name=\"kap1\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Es liegt ein Datensatz vor, der Daten zur chemischen Zusammensetzung von Rotweinen enthält und eine Aussage zur jeweiligen Qualität der Weine trifft. Es soll untersucht werden, ob die Weinqualität anhand der chemischen Daten bestimmt werden kann."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Datenverständnis <a name=\"kap2\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_path = \"M4_Video_Weinqualitaet.csv\"\n",
    "df = pd.read_csv(csv_path, sep=',', index_col=0)  \n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zum Datensatz: \n",
    "\n",
    "Der Datensatz enthält 1599 Zeilen, dies sind die chemischen Analysewerte von verschiedenen Rotweinproben, die ausgewertet wurden. Es wurden jeweils 12 Eigenschaften (= Spalten) erfasst. Die Namen der Spalten bedeuten folgendes:\n",
    "\n",
    "- `fixed acidity` = Festsäuregehalt \t\n",
    "- `volatile acidity` = Flüchtige Säuren\n",
    "- `citric acid` = Zitronensäuregehalt\n",
    "- `residual sugar` = Restzuckergehalt \n",
    "- `chlorides` = Chloride \t\n",
    "- `free sulfur dioxide` = Freier Schwefeldioxidgehalt\n",
    "- `total sulfur dioxide` Gesamt-Schwefeldioxidgehalt\n",
    "- `density` = Dichte\n",
    "- `pH` = pH-Wert\n",
    "- `sulphates` = Sulfatgehalt \t\n",
    "- `alcohol` = Alkoholgehalt\n",
    "- `quality` = Qualität\n",
    "\n",
    "Die *Qualität* wurde auf Grundlage sensorischer Daten erhoben und soll das Zielmerkmal dieser Modellbildung sein."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Für die Betrachtung dieses Problems ist es nicht nötig, chemisches Hintergrundwissen zu besitzen.  \n",
    "Grundsätzlich kann es aber zum Beispiel für die Featureauswahl, die Festlegung der Aufgabenstellung oder für die Implementierung des Modells nützlich sein, über das Hintergrundwissen des jeweiligen Datensatzes zu verfügen. Data Mining Probleme sind daher häufig interdisziplinäre Aufgabenfelder, in denen verschiedene Wissensgebiete zusammenfließen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Der Datensatz enthält 1599 Einträge. Für jedes Merkmal sind alle Felder vollständig gefüllt (Zur Erinnerung: Dies zeigt die Spalte `Non-Null Count` = 'Nicht-Null Anzahl' an. \n",
    "In der Spalte `Dtype` kann der Datentyp abgelesen werden. Alle Merkmale liegen als float vor, das Zielmerkmal `quality` ist als integer eingetragen)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alle enthaltenen Daten sind numerisch, sodass keine weiteren Anpassungen vorgenommen werden müssen. Die Merkmale haben jedoch unterschiedliche Größenordnungen, sodass eine Standardisierung der Daten vorgenommen werden sollte (s. [Kapitel 3.2](#kap32))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df.hist(figsize=(12,12));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die Histogramme zeigen, dass es keine Ausreißer gibt und die Merkmale sehr unterschiedlich verteilt sind.  \n",
    "Beim Merkmal `quality` fällt auf, dass die Verteilung der Einträge sehr ungleich ist: 1382 Einträge gehören der Qualität 0 (gut) an, während für die Weinqualität 1 (schlecht) nur 217 Daten vorliegen.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['quality'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Datenvorbereitung <a name=\"kap3\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>Arbeitsauftrag:</b> \n",
    "\n",
    "In diesem Kapitel soll der Wert vor allem auf den Verfahren liegen. Dennoch muss der Datensatz für die Modellierung vorbereitet werden. Führen Sie die einzelnen Schritte der Datenvorbereitung ([Kapitel 3](#kap3)) aus und lesen Sie die zugehörige Kommentierung. \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Aufteilung in Trainings- und Testdatensatz <a name=\"kap31\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Es wird wieder begonnen, den Datensatz mit `train_test_split` in einen Trainings- und einen Testdatensatz aufzuteilen (Erinnerung: Der Testdatensatz wird genutzt, um die Qualität des Modells zu überprüfen. Dazu werden die Merkmale des Testdatensatzes genutzt, um eine Vorhersage für das Zielmerkmal zu erstellen. Diese kann dann mit dem bekannten Zielmerkmal des Testdatensatzes abgeglichen werden).\n",
    "\n",
    "Dieser Schritt sollte vor der Modellierung und auch vor der weiteren Bearbeitung der Daten und der Featureauswahl erfolgen. Dadurch können die Testdaten so betrachtet werden, als würden diese gar nicht vorliegen. Das Modell und die zugehörigen Vorüberlegungen können so rein auf Grundlage der Trainingsdaten erstellt werden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_set,test_set = train_test_split(df, random_state=0, test_size=0.2, stratify = df['quality'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Standardisierung der Daten <a name=\"kap32\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wie bereits oben angekündigt, müssen die Daten vor der Modellierung umskaliert werden, da die Werte der Merkmale verschiedene Größenordnungen besitzen (z.B. im Schnitt 0.27 bei `citric acid` verglichen mit 46 bei`total sulfur dioxide`). Hier soll nun der `StandardScaler` (vergleiche Modul 3) verwendet werden. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Nur die Merkmale werden standardisiert, daher wird eine Liste erstellt, die nur die Merkmale ohne das Zielmerkmal enthält\n",
    "features = list(df.drop(['quality'], axis=1).columns)\n",
    "\n",
    "# Skalierung wird an train_set angepasst\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(train_set[features])\n",
    "\n",
    "# Skalierung der Trainingsdaten\n",
    "train_features_scaled = pd.DataFrame(scaler.transform(train_set[features]), columns=features, index=train_set.index)\n",
    "# Zusammenfügen der skalierten Merkmale und das Zielmerkmal (nicht skaliert) zu einem Dataframe\n",
    "train_set_scaled = pd.concat([train_features_scaled, train_set['quality']], axis=1)\n",
    "\n",
    "# Skalierung der Testdaten\n",
    "test_features_scaled = pd.DataFrame(scaler.transform(test_set[features]), columns=features, index=test_set.index)\n",
    "# Zusammenfügen der skalierten Merkmale und das Zielmerkmal (nicht skaliert) zu einem Dataframe\n",
    "test_set_scaled = pd.concat([test_features_scaled, test_set['quality']], axis=1)\n",
    "\n",
    "train_set_scaled.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Es ist zu beachten, dass nun die ursprünglichen Maßeinheiten keinen Sinn mehr ergeben und eine Transformation durchgeführt wurde, die chemisch gesehen keinen Sinn hat. Hier werden die Daten jedoch nicht aus der chemischen Perspektive, sondern als Data Science Projekt betrachtet, sodass hier alles erlaubt ist, was für die Modellierung die besten Ergebnisse liefert.\n",
    "\n",
    "Ein Blick auf die Statistiken der Daten zeigt, dass nun tatsächlich die Mittelwerte (mean) der transformierten Merkmale ungefähr 0 und die Standardabweichungen (std) ungefähr 1 sind:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "train_set_scaled.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3. Visualisierung <a name=\"kap33\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig=plt.figure(figsize=(15,10))\n",
    "columns = 4\n",
    "rows = 3\n",
    "for i in range(1, 12):\n",
    "    fig.add_subplot(rows, columns, i)\n",
    "    sns.barplot(x = 'quality', y = df.iloc[:,i-1], data=train_set_scaled) \n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die obige Darstellung lässt bereits erahnen, dass sich die Werte einiger Merkmale zwischen den Qualitäten nicht unterscheiden. Die ist beispielsweise beim pH-Wert (`pH`) und bei der Dichte (`density`) der Fall."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 Merkmalsauswahl anhand der Korrelationsmatrix <a name=\"kap34\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Der Eindruck aus der vorhergehenden Grafik lässt sich durch die Korrelationsmatrix noch vertiefen: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 7))\n",
    "sns.heatmap(train_set_scaled.corr(),annot=True, vmin=-1, vmax=1);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Es wird zunächst die Korrelation der Merkmale mit dem Ziel `quality` betrachtet:  \n",
    "- `alcohol` hat mit 0.44 die höchste Korrelation, gefolgt von\n",
    "- `volatile acidity` mit -0.28\n",
    "- `citric acid` mit 0.24\n",
    "- `sulphates` mit 0.2\n",
    "\n",
    "Bei der Betrachtung der Korrelation der Merkmale zueinander fällt auf, dass die Merkmale `volatile acidity` und `citric acid` miteinander korrelieren (-0.54). Aus diesem Grund wird `citric acid` nicht als Merkmal für die Modellierung genutzt.\n",
    "\n",
    "Die Grundlage für die Modellierung bilden somit die Merkmale:\n",
    "- `alcohol`\n",
    "- `volatile acidity` \n",
    "- `sulphates`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Modellierung <a name=\"kap4\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zunächst werden Trainings- und Testdaten auf die gewünschten Merkmale aus [Kapitel 3.4](#kap34) eingeschränkt: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trainingsdaten für die Modellierung mit ausgewählten Merkmalen\n",
    "X_train = train_set_scaled[['volatile acidity', 'sulphates', 'alcohol']]\n",
    "y_train = train_set_scaled[['quality']].values.ravel()\n",
    "\n",
    "# Testdaten für die Modellierung mit ausgewählten Merkmalen\n",
    "X_test = test_set_scaled[['volatile acidity', 'sulphates', 'alcohol']]\n",
    "y_test = test_set_scaled[['quality']].values.ravel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Entscheidungsbaum <a name=\"kap41\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entscheidungsbäume (Decision Trees) wurden bereits im End-to-end Projekt vorgestellt. Es handelt sich dabei um gerichtete Entscheidungsdiagramme.  \n",
    "Hierbei steht jede Ebene für eine Entscheidungsregel, deren Verzweigung zu weiteren Entscheidungsebenen führt. Dabei wird an jedem Knoten entschieden, ob ein Eintrag dem linken oder rechten Ast zugeordnet wird.\n",
    "Die letzte Ebene bildet die Ergebnissebene, die die Klasseneinteilung bestimmt.\n",
    "\n",
    "Entscheidungsbäume haben den großen Vorteil, dass ihre Ergebnisse \"interpretierbar\" sind, d.h. die Entscheidung, warum ein gewisser Eintrag im Datensatz einer gewissen Klasse zugeordnet wird, ist leicht nachvollziehbar. Diese Erklärbarkeit macht Entscheidungsbäume zu einem beliebten Machine Learning Verfahren, das häufig in Anwendungsgebieten wie der Medizintechnik, Pharmaindustrie und der Bankenbranche zum Einsatz kommt.\n",
    "\n",
    "Mathematisch werden die Entscheidungsregeln gebildet, indem mithilfe der Entropiefunktion oder dem Gini-Index bestimmt wird, wie viel Information in den Merkmalen enthalten ist und dann verglichen wird, welches Merkmal den größten \"Informationszuwachs\" liefert."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "clf_dt = DecisionTreeClassifier(max_depth = 2)\n",
    "clf_dt.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "_, ax = plt.subplots(figsize=(10,6))\n",
    "tree.plot_tree(clf_dt, feature_names=X_train.columns, class_names=['gut', 'schlecht'], filled=True);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nachfolgend werden die Gütemaße aus dem ersten Video des vierten Moduls bestimmt. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Korrektklassifikationsrate auf Trainingsdaten:\", clf_dt.score(X_train, y_train))\n",
    "print(\"Korrektklassifikationsrate auf Testdaten:\",clf_dt.score(X_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, recall_score, precision_score\n",
    "\n",
    "y_pred_dt = clf_dt.predict(X_test)\n",
    "print(confusion_matrix(y_test, y_pred_dt))\n",
    "print('Recall:', recall_score(y_test, y_pred_dt, zero_division=False))\n",
    "print('Precision:', precision_score(y_test, y_pred_dt, zero_division=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 kNN (k-Nächste Nachbarn) <a name=\"kap42\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Der kNN-Algorithmus ermittelt für ein neu zu klassifizierendes Beispiel die Nachbarn, also die (geometrisch betrachtet) umliegenden Beispiele. Die am häufigsten in der 'Nachbarschaft' vorkommende Klasse bestimmt dann die Klassenzuordnung. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die Standard Syntax für scikit-learn Verfahren funktioniert auch hier. Zunächst wird das k-Nächste Nachbarn Modell für k=1 angewendet:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "clf_nn = KNeighborsClassifier(1) # Initialisierung des Modells\n",
    "clf_nn.fit(X_train, y_train) # Trainieren des Modells anhand der Trainingsdaten"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Das so erstellte Modell kann nun auch auf die Testdaten angewandt werden.  \n",
    "Außerdem kann die Korrektklassifikationsrate des Modells auf die Trainings- und Testdaten, sowie die Konfusionsmatrix ausgegeben werden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_nn = clf_nn.predict(X_test)\n",
    "print(\"Korrektklassifikationsrate auf Trainingsdaten:\", clf_nn.score(X_train,y_train))\n",
    "print(\"Korrektklassifikationsrate auf Testdaten:\",clf_nn.score(X_test, y_test))\n",
    "print(confusion_matrix(y_test, y_pred_nn))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>Arbeitsauftrag:</b> \n",
    "\n",
    "Erforschen Sie die nachfolgend systematische Veränderung des Wertes k. \n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die Zahl der k-Nächsten Nachbarn wirkt sich auf das Modell aus. Daher wird im Folgenden ermittelt, welches k die \"besten\" Ergebnisse liefert."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Erstellen von zwei leeren Listen, in die die Korrektklassifikationsrate für die verschiedenen k eingetragen werden\n",
    "score_test = []\n",
    "score_train = []\n",
    "\n",
    "for k in range(1,10):\n",
    "    clf = KNeighborsClassifier(n_neighbors = k)\n",
    "    clf.fit(X_train, y_train)\n",
    "    s1 = clf.score(X_train, y_train)\n",
    "    s2 = clf.score(X_test, y_test)\n",
    "    score_train.append(s1)\n",
    "    score_test.append(s2)\n",
    "\n",
    "plt.plot(range(1,10),score_train, '-o', label=\"Trainingsdaten\");\n",
    "plt.plot(range(1,10),score_test, '-o', label = \"Testdaten\");\n",
    "plt.title(\"Korrektklassifikationsrate bei verschiedenen k's\");\n",
    "plt.xlabel(\"k\");\n",
    "plt.ylabel(\"Korrektklassifikationsrate\");\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Für das kNN-Modell wird k = 6 gewählt:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_nn_opt = KNeighborsClassifier(n_neighbors=6)\n",
    "clf_nn_opt.fit(X_train,y_train)\n",
    "print(\"Korrektklassifikationsrate auf Trainingsdaten:\", clf_nn_opt.score(X_train, y_train))\n",
    "print(\"Korrektklassifikationsrate auf Testdaten:\", clf_nn_opt.score(X_test, y_test))\n",
    "y_pred_nn_opt = clf_nn_opt.predict(X_test)\n",
    "print(confusion_matrix(y_test, y_pred_nn_opt))\n",
    "print('Precision:', precision_score(y_test, y_pred_nn_opt))\n",
    "print('Recall:', recall_score(y_test, y_pred_nn_opt))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 SVM (Support Vector Machine) <a name=\"kap43\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Im Gegensatz zum kNN-Algorithmus werden bei SVMs nicht die benachbarten Klassen gesucht, sondern es erfolgt eine geometrische Trennung der Klassen durch eine (ursprünglich) lineare Funktion. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die Standard Syntax für scikit-learn Verfahren funktioniert auch hier. Zunächst wird die SVM ohne Variation der Parameter angewendet:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "clf_svm = svm.SVC() # Initialisierung des Modells, hier SVC = Support Vector Classifier\n",
    "clf_svm.fit(X_train, y_train) # Trainieren des Modells anhand der Trainingsdaten"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Damit ergibt sich:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Korrektklassifikationsrate auf Trainingsdaten:\", clf_svm.score(X_train, y_train))\n",
    "print(\"Korrektklassifikationsrate auf Testdaten:\",clf_svm.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_svm = clf_svm.predict(X_test)\n",
    "print(confusion_matrix(y_test, y_pred_svm))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Fazit <a name=\"kap5\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Es wurden einige Klassifikationsverfahren vorgestellt, hierbei wurde...\n",
    "\n",
    "- festgestellt, dass mit Hilfe von sklearn die verschiedenen Modelle alle nach demselben Schema angewendet werden:\n",
    "    1. Importieren des Klassifikationsverfahren\n",
    "    2. Initiieren des Modells\n",
    "    3. Trainieren des Modells anhand der Trainingsdaten\n",
    "    4. Anwendung des trainierten Modells auf die Testdaten\n",
    "    5. Ausgabe der Gütemaße\n",
    "\n",
    "\n",
    "- in diesem Beispiel von allen Modellen eine hohe Korrektklassifikationsrate erreicht, wobei die Weine schlechter Qualität aber nur sehr schlecht erkannt werden. \n",
    "\n",
    "\n",
    "- festgestellt, dass eine genaue Betrachtung der Gütemaße in Bezug auf die Problemstellung nötig ist (bspw. \"wann Precision - wann Recall?\", bspw. \"ist die Korrektklassifikationsrate genau so aussagekräftig wie die Konfusionsmatrix?\"), um eine Aussage treffen zu können, ob es sich um ein gutes Modell handelt."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python-dali-dm"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
